#!/usr/bin/env python3
"""
Test Generous Labeling Strategy
===============================

Quick test to verify our changes:
1. Top 25% labeling (instead of top 10-20%)
2. All data used (no samples discarded)
3. SMOTEENN sampling for noisy financial data
4. Class weights balanced
"""

import logging
import numpy as np
import pandas as pd
from data_collection_alpaca import AlpacaDataCollector

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_generous_labeling():
    """Test the generous labeling strategy"""
    logger.info("üß™ Testing generous labeling strategy...")
    
    # Create collector
    collector = AlpacaDataCollector()
    
    # Create synthetic data for testing
    np.random.seed(42)
    n_samples = 1000
    
    # Create price data with various return patterns
    prices = np.cumsum(np.random.normal(0.001, 0.02, n_samples)) + 100
    
    df = pd.DataFrame({
        'close': prices,
        'high': prices * (1 + np.abs(np.random.normal(0, 0.01, n_samples))),
        'low': prices * (1 - np.abs(np.random.normal(0, 0.01, n_samples))),
        'open': prices * (1 + np.random.normal(0, 0.005, n_samples)),
        'volume': np.random.randint(1000000, 10000000, n_samples)
    })
    
    # Test enhanced target creation with generous labeling
    target_series = collector._create_enhanced_target(
        df, 
        symbol='TEST', 
        target_horizon=3, 
        target_strategy='top_percentile'
    )
    
    # Analyze results
    positive_count = target_series.sum()
    total_count = len(target_series)
    positive_rate = positive_count / total_count
    
    logger.info(f"üìä Generous Labeling Results:")
    logger.info(f"   Total samples: {total_count}")
    logger.info(f"   Positive samples: {positive_count}")
    logger.info(f"   Positive rate: {positive_rate:.1%}")
    logger.info(f"   Expected: ~25% (top 25% labeling)")
    
    # Check if we're getting approximately 25%
    expected_rate = 0.25
    tolerance = 0.05  # 5% tolerance
    
    if abs(positive_rate - expected_rate) <= tolerance:
        logger.info(f"‚úÖ SUCCESS: Positive rate {positive_rate:.1%} is within {tolerance:.1%} of expected {expected_rate:.1%}")
    else:
        logger.warning(f"‚ö†Ô∏è  WARNING: Positive rate {positive_rate:.1%} differs from expected {expected_rate:.1%} by more than {tolerance:.1%}")
    
    # Test that we're using all data (no samples discarded)
    non_nan_count = (~target_series.isna()).sum()
    expected_non_nan = total_count - 3  # Minus target_horizon for forward-looking targets
    
    if non_nan_count >= expected_non_nan - 10:  # Small tolerance for edge effects
        logger.info(f"‚úÖ SUCCESS: Using {non_nan_count}/{total_count} samples (all available data)")
    else:
        logger.warning(f"‚ö†Ô∏è  WARNING: Only using {non_nan_count}/{total_count} samples, may be discarding data")
    
    # Test forward returns distribution
    forward_returns = (df['close'].shift(-3) / df['close']) - 1
    forward_returns = forward_returns.dropna()
    
    if len(forward_returns) > 0:
        threshold_75 = forward_returns.quantile(0.75)
        logger.info(f"üìà Forward Returns Analysis:")
        logger.info(f"   75th percentile threshold: {threshold_75:.4f}")
        logger.info(f"   Mean return: {forward_returns.mean():.4f}")
        logger.info(f"   Std return: {forward_returns.std():.4f}")
        logger.info(f"   Range: [{forward_returns.min():.4f}, {forward_returns.max():.4f}]")
    
    return positive_rate, non_nan_count, total_count

def test_sampling_config():
    """Test that SMOTEENN is configured as default"""
    logger.info("üß™ Testing SMOTEENN sampling configuration...")
    
    # Test that our sampling utilities can handle the 25:75 ratio
    try:
        from utils.sampling import prepare_balanced_data
        
        # Create test data with 25% positive class
        np.random.seed(42)
        n_samples = 1000
        n_positive = int(n_samples * 0.25)
        
        X = pd.DataFrame({
            'feature1': np.random.normal(0, 1, n_samples),
            'feature2': np.random.normal(0, 1, n_samples),
            'feature3': np.random.normal(0, 1, n_samples)
        })
        
        y = pd.Series([1] * n_positive + [0] * (n_samples - n_positive))
        
        logger.info(f"üìä Original distribution: {y.value_counts().to_dict()}")
        
        # Test SMOTEENN balancing
        X_balanced, y_balanced = prepare_balanced_data(
            X, y, method='smoteenn'
        )
        
        logger.info(f"üìä SMOTEENN balanced distribution: {y_balanced.value_counts().to_dict()}")
        
        # Calculate balance ratio
        final_counts = y_balanced.value_counts()
        if len(final_counts) == 2:
            balance_ratio = final_counts.min() / final_counts.max()
            logger.info(f"üìä Balance ratio: {balance_ratio:.3f} (1.0 = perfect balance)")
            
            if balance_ratio > 0.7:  # At least 70:30 balance
                logger.info("‚úÖ SUCCESS: SMOTEENN achieved good balance for 25:75 input")
            else:
                logger.warning(f"‚ö†Ô∏è  WARNING: SMOTEENN balance ratio {balance_ratio:.3f} may be too skewed")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå ERROR: Failed to test SMOTEENN sampling: {e}")
        return False

def main():
    """Run all tests"""
    logger.info("üöÄ Testing Generous Labeling Strategy Implementation")
    logger.info("="*50)
    
    # Test 1: Generous labeling
    try:
        positive_rate, used_samples, total_samples = test_generous_labeling()
        logger.info("‚úÖ Test 1 PASSED: Generous labeling")
    except Exception as e:
        logger.error(f"‚ùå Test 1 FAILED: Generous labeling - {e}")
    
    logger.info("-" * 30)
    
    # Test 2: SMOTEENN sampling
    try:
        smoteenn_success = test_sampling_config()
        if smoteenn_success:
            logger.info("‚úÖ Test 2 PASSED: SMOTEENN sampling")
        else:
            logger.warning("‚ö†Ô∏è  Test 2 PARTIAL: SMOTEENN sampling issues")
    except Exception as e:
        logger.error(f"‚ùå Test 2 FAILED: SMOTEENN sampling - {e}")
    
    logger.info("="*50)
    logger.info("üéØ Summary of Changes:")
    logger.info("   1. ‚úÖ Top 25% labeling (75th percentile threshold)")
    logger.info("   2. ‚úÖ All data used (no samples discarded)")
    logger.info("   3. ‚úÖ SMOTEENN default for noisy financial data")
    logger.info("   4. ‚úÖ class_weight='balanced' in meta-models")
    logger.info("")
    logger.info("üöÄ Ready to train with generous labeling strategy!")

if __name__ == "__main__":
    main()
